<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Neural network back prop, with matrix fomulation</title>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<style type="text/css">
<!--
body { background-color:#ededed; font:norm2al 12px/18px Arial, Helvetica, sans-serif; }
h1 { display:block; width:600px; margin:20px auto; paddVing-bottom:20px; font:norm2al 24px/30px Georgia, "Times New Roman", Times, serif; color:#333; text-shadow: 1px 2px 3px #ccc; border-bottom:1px solid #cbcbcb; }
#container { width:600px; margin:0 auto; }
#myCanvas { background:#fff; border:1px solid #cbcbcb; }
#nav { display:block; width:100%; text-align:center; }
#nav li { display:block; font-weight:bold; line-height:21px; text-shadow:1px 1px 1px #fff; width:100px; height:21px; paddVing:5px; margin:0 10px; background:#e0e0e0; border:1px solid #ccc; -moz-border-radius:4px;-webkit-border-radius:4px; border-radius:4px; float:left; }
#nav li a { color:#000; display:block; text-decoration:none; width:100%; height:100%; }
-->
</style>
</head>
<script>

function RandomMat(inp,neurons)
{
    var L = []
    for(var i=0;i<neurons;i++)
    {
        L[i] = [];
        for(var j=0;j<inp;j++)
        {
            L[i].push(2*Math.random()-1);
        }
    }
    return L;
}

function PrintMat(m)
{
    var str = "[";
    for(var i=0;i<m.length;i++)
    {
        str += "[" + join(m[i][j],",") + "]";
    }
    str += "]\n";
    return str;
}

function MulMat(m1, m2)
{
    var O = [];        
    for(var j=0;j<m1.length;j++)
    {
        O[j]=[];
        for(var i=0;i<m2[0].length;i++)        
        {
            var tmp=0;
            for(var k=0;k<m1[0].length;k++)
            {
                tmp += (m1[j][k] * m2[k][i]);
            }
            O[j].push( tmp);
        }
    }
    return O;  
}


function TransposeMat(m)
{
    var O = [];        
    for(var j=0;j<m[0].length;j++)
    {
        O[j]=[];
        for(var i=0;i<m.length;i++)        
        {
            O[j][i] = m[i][j];
        }
    }
    return O;
}

function AddMat(m1, m2)
{
    var O = [];        
    for(var j=0;j<m1.length;j++)
    {
        O[j]=[];
        for(var i=0;i<m1[0].length;i++)        
        {
            O[j][i] = m1[j][i] + m2[j][i];
        }
    }
    return O;
}

function SimpleMulMat(m1, m2)
{
    var O = [];        
    for(var j=0;j<m1.length;j++)
    {
        O[j]=[];
        for(var i=0;i<m1[0].length;i++)        
        {
            O[j][i] = m1[j][i] * m2[j][i];
        }
    }
    return O;
}


function SubMat(m1, m2)
{
    var O = [];        
    for(var j=0;j<m1.length;j++)
    {
        O[j]=[];
        for(var i=0;i<m1[0].length;i++)        
        {
            O[j][i] = m1[j][i] - m2[j][i];
        }
    }
    return O;
}

function Act(x)
{
    return 1.0/(1.0+Math.exp(-x));
}

function DerAct(x)
{
    return x*(1-x);
}


function funcMat(func, m )
{
    var O = [];        
    for(var j=0;j<m.length;j++)
    {
        O[j]=[];
        for(var i=0;i<m[0].length;i++)        
        {
            O[j][i] = func(m[j][i]);
        }
    }
    return O;
}

function UpdateWeights(m1,m2, learningRate)
{
    for(var i=0;i<m1.length;i++)
    {
        for(var j=0;j<m1[0].length;j++)
        {
            m1[i][j] += learningRate * m2[i][j];
        }
    }
}

//-------------------------------

function GraphAxis()
{
    context.beginPath();
    context.strokeStyle="#000000";    
    context.moveTo(0,300-20); 
    context.lineTo(600,300-20);
    context.moveTo(20,0); 
    context.lineTo(20,300);
    context.closePath();
    context.stroke(); 
}

function Graph()
{
}

//-------------------------------


var wl_i1 = RandomMat(2,2);
var wl_12 = RandomMat(2,1);

wl_i1 = [ [1,2],[3,4] ];
wl_12 = [ [5,6] ];

var il    = [ [ [1],[0] ], [ [1],[1] ], [ [0],[1] ] , [ [0],[0] ] ];   //input
var t     = [ [ [1] ], [ [0] ], [ [1] ], [ [0] ] ];   //target

var iterations = 0;
var oldFitness=1000;
var curFitness=1000;
function iterate()
{
    var learningRate = 1;
    var err;
    var fitness=100;
    
    iterations++;
    
    var totalErr;
    
    //for(var j=0;j<100;j++)
    {
        totalErr = 0;
        for(var i=0;i<4;i++)
        {
            //forward pass
            //
            
            var o0   = il[i];
            var net1 = MulMat(wl_i1, o0);
            var o1   = funcMat(Act, net1);
            var net2 = MulMat(wl_12, o1); 
            var o2   = funcMat(Act, net2);

            err = SubMat(o2, t[i]);
            
            //back propagate
            //
            
            // outer layer
            var sp2  =  SimpleMulMat(funcMat(DerAct, net2), err);      
            var e2   = MulMat(sp2, TransposeMat(o1));
            
            // inner layer
            var wsp2   = MulMat(TransposeMat(wl_12), sp2);
            var sp1  =  SimpleMulMat(funcMat(DerAct, net1), wsp2);                  
            var e1   = MulMat(sp1, TransposeMat(o0));
            
            //update weights
            UpdateWeights(wl_12, e2, -learningRate);           
            UpdateWeights(wl_i1, e1, -learningRate);        
            
            totalErr += MulMat( err, TransposeMat(err))[0][0];
        }
        
    }    
    oldFitness = curFitness;    
    curFitness = totalErr;

    context.beginPath();
    context.strokeStyle="#ff0000";    
    context.moveTo((iterations-1)/20+20,300-oldFitness*50-20); 
    context.lineTo((iterations)/20+20,300-curFitness*50-20);
    context.closePath();
    context.stroke();        
    
    document.getElementById("text").innerHTML = "X axis, epochs: "+ iterations +"<br>Y axis, Error: "  + curFitness + "<br>";
}

function init()
{
    var myCanvas = document.getElementById("myCanvas");
    context = myCanvas.getContext('2d');
    context.clearRect(0,0,600,300);
    GraphAxis();
    setInterval(iterate,10); 
}
</script>


<body onload="init()">
<h1>Neural network back prop, with matrix fomulation</h1>
<div id="container">
	
<canvas id="myCanvas" width="600" height="300"></canvas>

<div id="text"></div>

<h2>Intro</h2>

In this tutorial we are going to derive the matrix formualtion for the forward and the back propagation passes.

Let's think about a 2x2 neural netork
<pre>
              F          H
i1 o-------a--o-------e--o
    \        / \        /
     \      /   \      /
      \    b     \    f
       \  /       \  /          
        \/         \/  
        /\         /\                                   
       /  \       /  \ 
      /    c     /    g                               
     /      \   /      \                                   
    /        \ /        \                                       
i2 o-------d--o-------h--o
              G          I
</pre>

$$\require{cancel}$$

$$H = \sigma(net_H) =  \sigma(e\cdot F+f\cdot G)$$
$$I = \sigma(net_I) =  \sigma(g\cdot F+h\cdot G)$$
$$F = \sigma(net_F) =  \sigma(a\cdot i_1 + b\cdot i_2)$$
$$G = \sigma(net_G) =  \sigma(c\cdot i_1 + d\cdot i_2)$$

We are starting to see some matrices here...

$$\begin{pmatrix}net_H\\
net_I\\
\end{pmatrix} = \begin{pmatrix} e & f \\ g & h
\end{pmatrix} \cdot \begin{pmatrix}F\\
G\\
\end{pmatrix}$$

$$\begin{pmatrix}net_F\\
net_G\\
\end{pmatrix} = \begin{pmatrix} a & b \\ c & d
\end{pmatrix} \cdot \begin{pmatrix}i_1\\
i_2\\
\end{pmatrix}$$

being the outputs of the neurons then:

$$\begin{pmatrix}H\\
I\\
\end{pmatrix} = \sigma \Bigg( \begin{pmatrix}net_H\\
net_I\\
\end{pmatrix} \Bigg)
$$ 

$$\begin{pmatrix}F\\
G\\
\end{pmatrix} = \sigma \Bigg( \begin{pmatrix}i_1\\
i_2\\
\end{pmatrix} \Bigg)
$$ 

And the full forward operation woudl be given by:
 
$$\begin{pmatrix}H\\
I\\
\end{pmatrix} = \sigma \Bigg( \begin{pmatrix} e & f \\ g & h
\end{pmatrix} \cdot \sigma \Bigg( \begin{pmatrix} a & b \\ c & d
\end{pmatrix} \cdot \begin{pmatrix}i_1\\
i_2\\
\end{pmatrix} \Bigg) \Bigg)
$$ 
 
Now we want to see how $H$ and $I$ change when the weights $a ... b$ change. This is given by the derivative.<br>
<br>
For computing derivatives we'll be using the chain rule. We'll need some formulas:
$$ \frac{d\sigma(f(...))}{df(...)} = \sigma'(f(...)) \cdot f'(...)'$$

$$\frac{\partial{H}}{\partial{e}} = \sigma'(net_H) \frac{\partial{(net_H)}}{\partial{e}} =\sigma'(net_H)  \frac{\partial{(e\cdot F+f\cdot G)}}{\partial{e}} = \sigma'(net_H) F$$
$$\frac{\partial{H}}{\partial{f}} = \sigma'(net_H) \frac{\partial{(net_H)}}{\partial{f}} =\sigma'(net_H)  \frac{\partial{(e\cdot F+f\cdot G)}}{\partial{f}} = \sigma'(net_H) G$$
$$\frac{\partial{I}}{\partial{g}} = \sigma'(net_I) \frac{\partial{(net_I)}}{\partial{g}} =\sigma'(net_I)  \frac{\partial{(g\cdot F+h\cdot G)}}{\partial{g}} = \sigma'(net_I) F$$
$$\frac{\partial{I}}{\partial{h}} = \sigma'(net_I) \frac{\partial{(net_I)}}{\partial{h}} =\sigma'(net_I)  \frac{\partial{(g\cdot F+h\cdot G)}}{\partial{h}} = \sigma'(net_I) G$$

Starting from the output we immediatelly see a jacobian:

$$\begin{pmatrix}\frac{\partial{H}}{\partial{e}} & \frac{\partial{H}}{\partial{f}} \\ 
\frac{\partial{I}}{\partial{g}} & \frac{\partial{I}}{\partial{h}}\\
\end{pmatrix} = \begin{pmatrix} \sigma'(net_H) F & \sigma'(net_H) G \\ \sigma'(net_I)F & \sigma'(net_I)G\end{pmatrix} = \sigma'(\begin{pmatrix}net_H\\
net_I\\
\end{pmatrix}) \cdot \begin{pmatrix} F  & G \end{pmatrix}$$

Let see how the outputs change with the weights $a .. d$:<br><br>

For H:

$$\frac{\partial{H}}{\partial{a}} = \sigma'(net_H) \frac{\partial{(net_H)}}{\partial{a}} =\sigma'(net_H)  \frac{\partial{(e\cdot \sigma(net_F)+f\cdot G)}}{\partial{a}} = \sigma'(net_H) \cdot e\cdot \sigma'(net_F) \cdot i_1$$
$$\frac{\partial{H}}{\partial{b}} = \sigma'(net_H) \frac{\partial{(net_H)}}{\partial{b}} =\sigma'(net_H)  \frac{\partial{(e\cdot \sigma(net_F)+f\cdot G)}}{\partial{b}} = \sigma'(net_H) \cdot e\cdot \sigma'(net_F) \cdot i_2$$

$$\frac{\partial{H}}{\partial{c}} = \sigma'(net_H) \frac{\partial{(net_H)}}{\partial{c}} =\sigma'(net_H)  \frac{\partial{(e\cdot F+f\cdot \sigma(net_G))}}{\partial{c}} = \sigma'(net_H) \cdot f\cdot \sigma'(net_G) \cdot i_1$$
$$\frac{\partial{H}}{\partial{d}} = \sigma'(net_H) \frac{\partial{(net_H)}}{\partial{d}} =\sigma'(net_H)  \frac{\partial{(e\cdot F+f\cdot \sigma(net_G))}}{\partial{d}} = \sigma'(net_H) \cdot f\cdot \sigma'(net_G) \cdot i_2$$

For I:

$$\frac{\partial{I}}{\partial{a}} = \sigma'(net_I) \frac{\partial{(net_I)}}{\partial{a}} =\sigma'(net_I)  \frac{\partial{(g\cdot \sigma(net_G)+h\cdot H)}}{\partial{a}} = \sigma'(net_I) \cdot g\cdot \sigma'(net_F) \cdot i_1$$
$$\frac{\partial{I}}{\partial{b}} = \sigma'(net_I) \frac{\partial{(net_I)}}{\partial{b}} =\sigma'(net_I)  \frac{\partial{(g\cdot \sigma(net_G)+h\cdot H)}}{\partial{b}} = \sigma'(net_I) \cdot g\cdot \sigma'(net_F) \cdot i_2$$

$$\frac{\partial{I}}{\partial{c}} = \sigma'(net_I) \frac{\partial{(net_I)}}{\partial{c}} =\sigma'(net_I)  \frac{\partial{(g\cdot G+h\cdot \sigma(net_H))}}{\partial{c}} = \sigma'(net_I) \cdot h\cdot \sigma'(net_G) \cdot i_1$$
$$\frac{\partial{I}}{\partial{d}} = \sigma'(net_I) \frac{\partial{(net_I)}}{\partial{d}} =\sigma'(net_I)  \frac{\partial{(g\cdot G+h\cdot \sigma(net_H))}}{\partial{d}} = \sigma'(net_I) \cdot h\cdot \sigma'(net_G) \cdot i_2$$




Now we have all the ingredients to train our network:

First we need a forward pass, we take the output and we compute how far are we from the target result $t_1 and t_2$:

$$Error = (H-t_1)^2 + (I-t_2)^2$$

And it's derivative is:

$$d(Error) = 2(H-t_1)dH + 2(I-t_2)dI= 2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
dH\\
dI
\end{pmatrix}$$

Its partial derivatives are:

$$\frac{\partial{Error}}{\partial{e}} = 2(H-t_1)dH + 2(I-t_2)dI= 2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\frac{\partial{H}}{\partial{e}}\\
\cancelto{0}{\frac{\partial{I}}{\partial{e}}}
\end{pmatrix} = 2(H-t_1) \frac{\partial{H}}{\partial{e}}     $$

$$\frac{\partial{Error}}{\partial{e}} = 2(H-t_1) \frac{\partial{H}}{\partial{e}} =  2(H-t_1) \sigma(net_H)F    $$
$$\frac{\partial{Error}}{\partial{f}} = 2(H-t_1) \frac{\partial{H}}{\partial{f}} =  2(H-t_1) \sigma(net_H)G     $$

$$\frac{\partial{Error}}{\partial{g}} = 2(I-t_2) \frac{\partial{I}}{\partial{g}}  =  2(I-t_2) \sigma(net_I)F    $$
$$\frac{\partial{Error}}{\partial{h}} = 2(I-t_2) \frac{\partial{I}}{\partial{h}}  =  2(I-t_2) \sigma(net_I)G   $$


rearranging:

$$ \begin{pmatrix}\frac{\partial{E}}{\partial{e}} & \frac{\partial{E}}{\partial{f}} \\ 
\frac{\partial{E}}{\partial{g}} & \frac{\partial{E}}{\partial{h}}\\
\end{pmatrix} = 2 \cdot  
\begin{pmatrix}
\sigma'(net_H) \cdot (H-t_1) \\
\sigma'(net_I) \cdot (I-t_2) \\
\end{pmatrix} 
\cdot 
\begin{pmatrix} F  & G \end{pmatrix}  
= \begin{pmatrix}
\sigma'(net_H) & 0 \\
0 & \sigma'(net_I)\\
\end{pmatrix} 
\cdot 
2 
\cdot
\begin{pmatrix}
(H-t_1) \\
(I-t_2) \\
\end{pmatrix} 
\cdot 
\begin{pmatrix} F  & G \end{pmatrix}  
$$

and in a similar way:

$$\frac{\partial{Error}}{\partial{a}} = 2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\frac{\partial{H}}{\partial{a}}\\
\frac{\partial{I}}{\partial{a}}
\end{pmatrix} =   2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\sigma'(net_H) \cdot e\cdot \sigma'(net_F) \cdot i_1\\
\sigma'(net_I) \cdot g\cdot \sigma'(net_F) \cdot i_1
\end{pmatrix} $$

$$\frac{\partial{Error}}{\partial{b}} = 2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\frac{\partial{H}}{\partial{b}}\\
\frac{\partial{I}}{\partial{b}}
\end{pmatrix} =   2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\sigma'(net_H) \cdot e\cdot \sigma'(net_F) \cdot i_2\\
\sigma'(net_I) \cdot g\cdot \sigma'(net_F) \cdot i_2
\end{pmatrix} $$

$$\frac{\partial{Error}}{\partial{c}} = 2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\frac{\partial{H}}{\partial{c}}\\
\frac{\partial{I}}{\partial{c}}
\end{pmatrix} =   2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\sigma'(net_H) \cdot f\cdot \sigma'(net_G) \cdot i_1\\
\sigma'(net_I) \cdot h\cdot \sigma'(net_G) \cdot i_1
\end{pmatrix} $$

$$\frac{\partial{Error}}{\partial{d}} = 2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\frac{\partial{H}}{\partial{d}}\\
\frac{\partial{I}}{\partial{d}}
\end{pmatrix} =   2\begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\sigma'(net_H) \cdot f\cdot \sigma'(net_G) \cdot i_2\\
\sigma'(net_I) \cdot h\cdot \sigma'(net_G) \cdot i_2
\end{pmatrix} $$

simplifying a bit

$$\frac{\partial{Error}}{\partial{a}} = 
2\cdot \sigma'(net_F) \cdot i_1 \cdot \begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\sigma'(net_H) \cdot e \\
\sigma'(net_I) \cdot g
\end{pmatrix} = 2\cdot \sigma'(net_F) \cdot i_1 \cdot (((H-t_1) \cdot \sigma'(net_H) \cdot e)  + ((I-t_2) \cdot \sigma'(net_I) \cdot g))
 $$

$$\frac{\partial{Error}}{\partial{b}} = 
2\cdot \sigma'(net_F) \cdot i_2 \cdot \begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\sigma'(net_H) \cdot e\\
\sigma'(net_I) \cdot g 
\end{pmatrix} = 2\cdot \sigma'(net_F) \cdot i_2 \cdot (((H-t_1) \cdot \sigma'(net_H) \cdot e)  + ((I-t_2) \cdot \sigma'(net_I) \cdot g))$$

$$\frac{\partial{Error}}{\partial{c}} = 
2\cdot \sigma'(net_G) \cdot i_1 \cdot \begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\sigma'(net_H) \cdot f \\
\sigma'(net_I) \cdot h
\end{pmatrix} = 2\cdot \sigma'(net_G) \cdot i_1 \cdot (((H-t_1) \cdot \sigma'(net_H) \cdot f)  + ((I-t_2) \cdot \sigma'(net_I) \cdot h))$$

$$\frac{\partial{Error}}{\partial{d}} = 
2\cdot \sigma'(net_G) \cdot i_2 \cdot \begin{pmatrix} (H-t_1) & (I-t_2) \end{pmatrix} \cdot \begin{pmatrix}
\sigma'(net_H) \cdot f \\
\sigma'(net_I) \cdot h 
\end{pmatrix} = 2\cdot \sigma'(net_G) \cdot i_2 \cdot (((H-t_1) \cdot \sigma'(net_H) \cdot f)  + ((I-t_2) \cdot \sigma'(net_I) \cdot h))$$

hence

$$ \begin{pmatrix}\frac{\partial{E}}{\partial{a}} & \frac{\partial{E}}{\partial{b}} \\ 
\frac{\partial{E}}{\partial{c}} & \frac{\partial{E}}{\partial{d}}\\
\end{pmatrix} =  
\begin{pmatrix}
\sigma'(net_F) & 0 \\
0 & \sigma'(net_G)\\
\end{pmatrix} 
\cdot 
\begin{pmatrix}
e & g \\
f & h\\
\end{pmatrix} 
\cdot 
\Bigg[
2 \cdot 
\begin{pmatrix}
\sigma'(net_H) \cdot (H-t_1) \\
\sigma'(net_I) \cdot (I-t_2) \\
\end{pmatrix}
\Bigg]
\cdot 
\begin{pmatrix}
i_1 & i_2 \\
\end{pmatrix}
$$ 

Notice how the expression within aquare brackes was computed early before.

Let's now generalize the above structure for any network.. 
 
</br>
</br>
<h2>Contact/Questions:</h2>
 &lt;my_github_account_username&gt;$@gmail.com$.
</br>
</br>
</div>
</body>
</html>
